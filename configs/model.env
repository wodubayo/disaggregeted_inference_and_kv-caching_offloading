MODEL_ID=meta-llama/Llama-3.2-3B-Instruct
MAX_MODEL_LEN=8192
GPU_MEMORY_UTILIZATION=0.90
SWAP_SPACE_GB=8
LMCACHE_PATH=/data/kv_cache
DEFAULT_MAX_TOKENS=256
DEFAULT_TEMPERATURE=0.2